# LLM-Powered-Booking-Analytics-QA-System ğŸš€

A **Retrieval-Augmented Generation (RAG) chatbot** using **FastAPI, FAISS, and LangChain**.  
It can **answer booking-related queries** and **perform calculations**.

---

## **âš¡ Features**
- **Natural Language Querying**: Retrieve hotel booking insights.
- **Vector Search with FAISS**: Stores embeddings for fast retrieval.
- **Math Calculation Support**: Can process and return mathematical computations.
- **FastAPI Backend**: REST API for chatbot queries.
- **Streamlit Frontend**: Simple UI for chat.

---

## **ğŸ”¹Prerequisites**
Before running the project, ensure the following dependencies are installed:
1. **Install Ollama and Nomic Embeddings**
Download and Install Ollama: https://ollama.com/download
Run in Terminal:
```sh
ollama run gemma2
ollama pull nomic-embed-text
```
2. **Generate Vector Embeddings**
- Run RAG.ipynb to process the dataset and save the FAISS index.
- This step is necessary for enabling retrieval-augmented generation (RAG).

3. Ensure Proper Directory Structure
```sh
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ routes.py
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ chatbot.py
â”œâ”€â”€ vector_db
â”‚   â”œâ”€â”€ index.faiss
â”‚   â”œâ”€â”€ index.pkl
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ hotel_bookings_cleaned.csv
â”œâ”€â”€ RAG.ipynb
â”œâ”€â”€ README.md

```

---

## **ğŸ”¹ Setup Instructions**
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/ankushmehta123/LLM-Powered-Booking-Analytics-QA-System.git
cd LLM-Powered-Booking-Analytics-QA-System
```

### **2ï¸âƒ£ Setup the Virtual Environment**
```sh
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### **3ï¸âƒ£ Install Dependencies**

#### Backend Dependencies
```sh
cd backend
pip install -r requirements.txt
```
#### Frontend Dependencies
```sh
cd ../frontend
pip install -r requirements.txt
```

---

## **ğŸ”¹ Running the Application**
### **1ï¸âƒ£ Start FastAPI Backend**
```sh
cd backend
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

### **2ï¸âƒ£ Run the Chatbot (CLI)**
```sh
cd ../frontend
python chatbot.py
```

---

## ğŸ”¹ API Endpoints

| **Method** | **Endpoint**            | **Description**                          |
|-----------|-------------------------|------------------------------------------|
| `POST`    | `/`                   | Ask a question using RAG                |
| `GET`     | `/revenue_trends/`       | Get revenue trends (requires `year` & `month`) |
| `GET`     | `/cancellations/`        | Get cancellations (requires `year`, `month`, `day`) |

### ğŸ”¹ Example Query

#### **ğŸ“Œ Ask a question using RAG**
```sh
curl -X 'POST' 'http://127.0.0.1:8000/' \
-H 'Content-Type: application/json' \
-d '{"query": "What is the highest revenue year?"}'
```
